from answer_feedback import create_feedback_client, get_similar_negative_feedback, save_feedback_to_supabase
from dotenv import load_dotenv
from langchain.chains import LLMChain
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableMap
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from utils import extract_links
from web_crawling import get_dynamic_page_text
from web_search import search_serper_links

import os
import streamlit as st

load_dotenv()
supabase_client = create_feedback_client()

llm = ChatOpenAI(model="gpt-4.1", temperature=0.2) # GPT LLM êµ¬ì„±
memory = ConversationBufferMemory(return_messages=True) # ë©”ëª¨ë¦¬ ì„¤ì • (ì´ì „ ëŒ€í™” ê¸°ì–µ)
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ë²•ì  ì´ìŠˆë¥¼ ë¶„ë¥˜í•˜ê³ , ì‹¤ì œ ê³µê³µê¸°ê´€ ì •ë³´ë¥¼ í™œìš©í•´ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”."),
    MessagesPlaceholder(variable_name="history"),
    ("user", "{user_input}")
])
output_parser = StrOutputParser() # ì¶œë ¥ íŒŒì„œ
chain = LLMChain(llm=llm, prompt=prompt, memory=memory, output_parser=StrOutputParser()) # LLMChainìœ¼ë¡œ ëŒ€í™”í˜• ì±— êµ¬ì„±


issue_prompt = ChatPromptTemplate.from_messages([ # ì´ìŠˆ ë¶„ë¥˜ìš© í”„ë¡¬í”„íŠ¸
    ("system", "ë‹¤ìŒ ì‚¬ìš©ìì˜ ë¬¸ì¥ì€ ì–´ë–¤ ë²•ì  ì´ìŠˆì— í•´ë‹¹í•˜ëŠ”ì§€ í•œ ë‹¨ì–´ ë˜ëŠ” ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”. (ì˜ˆ: ì„ê¸ˆì²´ë¶ˆ, ë¶€ë‹¹í•´ê³ , ê°œì¸ì •ë³´ ìœ ì¶œ ë“±)"),
    ("user", "{user_input}")
])
issue_chain = LLMChain( # ì´ìŠˆ ë¶„ë¥˜ LLMChain
    llm=ChatOpenAI(model="gpt-4.1", temperature=0.0),
    prompt=issue_prompt,
    output_parser=StrOutputParser()
)

# Streamlit ì•±
st.set_page_config(page_title="ë²•ë¥  ìƒë‹´ ì±—ë´‡", layout="wide")
st.markdown("## ğŸ§‘â€âš–ï¸ ë²•ë¥  ì±—ë´‡ (LangChain + GPT)")

# ëŒ€í™” ì…ë ¥
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

for role, msg in st.session_state.chat_history:
    with st.chat_message("user" if role == "ğŸ§‘â€ğŸ’¼ ì§ˆë¬¸" else "assistant"):
        st.markdown(msg if role != "ğŸ§‘â€ğŸ’¼ ì§ˆë¬¸" else f"**{msg}**")

# ì…ë ¥ì´ ìˆëŠ” ê²½ìš° â†’ ë‹µë³€ ë°›ê³  ì¶œë ¥
if user_input:
    with st.chat_message("user"):
        st.markdown(f"**{user_input}**")

    with st.chat_message("assistant"):
        with st.spinner("GPTê°€ í•´ê²° ë°©ì•ˆì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # 1ï¸âƒ£ GPTë¡œ ë²•ì  ì´ìŠˆ ë¶„ë¥˜
            issue_type = issue_chain.run({"user_input": user_input}).strip()
            st.markdown(f"ğŸ§  ê°ì§€ëœ ë²•ì  ì´ìŠˆ: **{issue_type}**")

            # 2ï¸âƒ£ Serper ê²€ìƒ‰ (ë¬¸ì œ ìœ í˜• ê¸°ë°˜)
            SERPER_API_KEY = os.getenv("SERPER_API_KEY")  # .envì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
            query = f"{issue_type} ê´€ë ¨ ì‹ ê³  ì ˆì°¨ site:moel.go.kr OR site:gov.kr OR site:minwon.go.kr"
            
            urls = search_serper_links(query, api_key=SERPER_API_KEY)
            first_url = urls[0] if urls else None

            # for url in urls: # í¬ë¡¤ë§ í›„ë³´êµ° ë””ë²„ê¹…ìš© UI
            #     st.markdown(f'í¬ë¡¤ë§ í›„ë³´êµ°: {url}')

            page_text = get_dynamic_page_text(first_url) if first_url else "[ê´€ë ¨ í˜ì´ì§€ ì—†ìŒ]"

            # 3ï¸âƒ£ GPTì—ê²Œ í•´ê²° ë°©ì•ˆ ìš”ì²­
            feedback = get_similar_negative_feedback(supabase_client, user_input) # ì´ì „ì— ë¶€ì •ì ì¸ í”¼ë“œë°±ì´ ìˆì—ˆëŠ”ì§€ supabase ì¡°íšŒ
            if feedback: # ìˆì—ˆë‹¤ë©´
                prompt_extra = f"""
            ê³¼ê±° ë¹„ìŠ·í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ GPT ì‘ë‹µì´ ìˆì—ˆê³ , ì‚¬ìš©ìëŠ” ì´ë¥¼ 'ë¶€ì¡±í•˜ë‹¤'ê³  í‰ê°€í–ˆìŠµë‹ˆë‹¤:

            ì§ˆë¬¸: {feedback['question']}
            ì‘ë‹µ: {feedback['answer']}

            â†’ ì´ë²ˆì—ëŠ” ë” êµ¬ì²´ì ì¸ ì•ˆë‚´ (ê¸°ê´€ëª…, ì‹ ê³  ì ˆì°¨, ì„œë¥˜ëª… ë“±)ë¥¼ í¬í•¨í•˜ì—¬ ë‹¤ì‹œ ë‹µë³€í•´ì£¼ì„¸ìš”.
            """
                enriched_input = prompt_extra + "\n\ní˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸: " + user_input
            else: # ì—†ë‹¤ë©´
                enriched_input = user_input

            # ìµœì¢… GPT ì…ë ¥ êµ¬ì„±
            combined_input = f"{enriched_input}\n\n[ê³µê³µê¸°ê´€ ë³¸ë¬¸ ìš”ì•½ ì°¸ê³ ]\n{page_text}"
            response = chain.run({"user_input": combined_input})

            # ğŸ§¾ GPT ë‹µë³€ ì¶œë ¥
            st.markdown(response)

            # ğŸ” ì‘ë‹µì—ì„œ ë§í¬ ëª¨ë‘ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ + ì¼ë°˜ URL + HTML ë§í¬)
            urls = extract_links(response)
            if urls:
                with st.expander("ğŸ”— ê´€ë ¨ ë§í¬ ë³´ê¸°"):
                    for url in urls[:3]:
                        st.markdown(f"- [{url}]({url})")
            else: st.info("ğŸ”— GPT ì‘ë‹µì— ë§í¬ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            with st.expander("ğŸ“ ì°¸ê³ í•œ í˜ì´ì§€ ë³¸ë¬¸ ë³´ê¸°"):
                st.markdown(f'ì°¸ê³ í•œ í˜ì´ì§€ ë§í¬: {first_url}')
                st.markdown(page_text if page_text else "_ë³¸ë¬¸ ì—†ìŒ_")
            
            # ì‚¬ìš©ì í‰ê°€ ë²„íŠ¼
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸ‘ ë„ì›€ì´ ë˜ì—ˆì–´ìš”", key="thumbs_up"):
                    st.success("ê°ì‚¬í•©ë‹ˆë‹¤! ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤.")
                    save_feedback_to_supabase(supabase_client, user_input, response, issue_type, "ğŸ‘")
            with col2:
                if st.button("ğŸ‘ ë¶€ì¡±í–ˆì–´ìš”", key="thumbs_down"):
                    st.warning("ì£„ì†¡í•©ë‹ˆë‹¤. ë” ë‚˜ì€ ë‹µë³€ì„ ìœ„í•´ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤.")
                    save_feedback_to_supabase(supabase_client, user_input, response, issue_type, "ğŸ‘")

    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.chat_history.append(("ğŸ§‘â€ğŸ’¼ ì§ˆë¬¸", user_input))
    st.session_state.chat_history.append(("ğŸ¤– GPT", response))