from answer_feedback import create_feedback_client, get_similar_negative_feedback, save_feedback_to_supabase
from dotenv import load_dotenv
from langchain.chains import LLMChain
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableMap
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from utils import extract_links
from web_crawling import get_dynamic_page_text
from web_search import search_serper_links

import os
import streamlit as st

load_dotenv()
supabase_client = create_feedback_client()

llm = ChatOpenAI(model="gpt-4.1", temperature=0.2) # GPT LLM êµ¬ì„±
memory = ConversationBufferMemory(return_messages=True) # ë©”ëª¨ë¦¬ ì„¤ì • (ì´ì „ ëŒ€í™” ê¸°ì–µ)
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ë²•ì  ì´ìŠˆë¥¼ ë¶„ë¥˜í•˜ê³ , ì‹¤ì œ ê³µê³µê¸°ê´€ ì •ë³´ë¥¼ í™œìš©í•´ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”."),
    MessagesPlaceholder(variable_name="history"),
    ("user", "{user_input}")
])
output_parser = StrOutputParser() # ì¶œë ¥ íŒŒì„œ
chain = LLMChain(llm=llm, prompt=prompt, memory=memory, output_parser=StrOutputParser()) # LLMChainìœ¼ë¡œ ëŒ€í™”í˜• ì±— êµ¬ì„±


issue_prompt = ChatPromptTemplate.from_messages([ # ì´ìŠˆ ë¶„ë¥˜ìš© í”„ë¡¬í”„íŠ¸
    ("system", "ë‹¤ìŒ ì‚¬ìš©ìì˜ ë¬¸ì¥ì€ ì–´ë–¤ ë²•ì  ì´ìŠˆì— í•´ë‹¹í•˜ëŠ”ì§€ í•œ ë‹¨ì–´ ë˜ëŠ” ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”. (ì˜ˆ: ì„ê¸ˆì²´ë¶ˆ, ë¶€ë‹¹í•´ê³ , ê°œì¸ì •ë³´ ìœ ì¶œ ë“±)"),
    ("user", "{user_input}")
])
issue_chain = LLMChain( # ì´ìŠˆ ë¶„ë¥˜ LLMChain
    llm=ChatOpenAI(model="gpt-4.1", temperature=0.0),
    prompt=issue_prompt,
    output_parser=StrOutputParser()
)

# Streamlit ì•±
st.set_page_config(page_title="ë²•ë¥  ìƒë‹´ ì±—ë´‡", layout="wide")
st.markdown("## ğŸ§‘â€âš–ï¸ ë²•ë¥  ì±—ë´‡ (LangChain + GPT)")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

for role, msg in st.session_state.chat_history:
    with st.chat_message("user" if role == "ğŸ§‘â€ğŸ’¼ ì§ˆë¬¸" else "assistant"):
        st.markdown(msg if role != "ğŸ§‘â€ğŸ’¼ ì§ˆë¬¸" else f"**{msg}**")

# ì…ë ¥ì´ ìˆëŠ” ê²½ìš° â†’ ë‹µë³€ ë°›ê³  ì¶œë ¥
if st.session_state.get("trigger_gpt", False):
    st.session_state.trigger_gpt = False
    user_input = st.session_state.user_input

    with st.chat_message("user"):
        st.markdown(f"**{user_input}**")

    with st.chat_message("assistant"):
        try:
            with st.spinner("GPTê°€ í•´ê²° ë°©ì•ˆì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                issue_type = issue_chain.run({"user_input": user_input}).strip()
                st.markdown(f"ğŸ§  ê°ì§€ëœ ë²•ì  ì´ìŠˆ: **{issue_type}**")

                SERPER_API_KEY = os.getenv("SERPER_API_KEY")
                query = f"{issue_type} ê´€ë ¨ ì‹ ê³  ì ˆì°¨ site:moel.go.kr OR site:gov.kr OR site:minwon.go.kr"
                urls = search_serper_links(query, api_key=SERPER_API_KEY)
                first_url = urls[0] if urls else None
                page_text = get_dynamic_page_text(first_url) if first_url else "[ê´€ë ¨ í˜ì´ì§€ ì—†ìŒ]"

                feedback = get_similar_negative_feedback(supabase_client, user_input)
                if feedback:
                    prompt_extra = f"""
                    ê³¼ê±° ë¹„ìŠ·í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ GPT ì‘ë‹µì´ ìˆì—ˆê³ , ì‚¬ìš©ìëŠ” ì´ë¥¼ 'ë¶€ì¡±í•˜ë‹¤'ê³  í‰ê°€í–ˆìŠµë‹ˆë‹¤:

                    ì§ˆë¬¸: {feedback['question']}
                    ì‘ë‹µ: {feedback['answer']}

                    â†’ ì´ë²ˆì—ëŠ” ë” êµ¬ì²´ì ì¸ ì•ˆë‚´ (ê¸°ê´€ëª…, ì‹ ê³  ì ˆì°¨, ì„œë¥˜ëª… ë“±)ë¥¼ í¬í•¨í•˜ì—¬ ë‹¤ì‹œ ë‹µë³€í•´ì£¼ì„¸ìš”.
                    """
                    enriched_input = prompt_extra + "\n\ní˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸: " + user_input
                else:
                    enriched_input = user_input

                combined_input = f"{enriched_input}\n\n[ê³µê³µê¸°ê´€ ë³¸ë¬¸ ìš”ì•½ ì°¸ê³ ]\n{page_text}"
                print("ğŸ§ª GPT ì‘ë‹µ ì „ ì‹¤í–‰ ë„ë‹¬")
                response = chain.run({"user_input": combined_input})
                print("âœ… GPT ì‘ë‹µ ì™„ë£Œ")

                st.session_state.last_input = user_input
                st.session_state.last_response = response
                st.session_state.last_issue = issue_type

                st.markdown(response)

                urls = extract_links(response)
                if urls:
                    with st.expander("ğŸ”— ê´€ë ¨ ë§í¬ ë³´ê¸°"):
                        for url in urls[:3]:
                            st.markdown(f"- [{url}]({url})")
                else:
                    st.info("ğŸ”— GPT ì‘ë‹µì— ë§í¬ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                with st.expander("ğŸ“ ì°¸ê³ í•œ í˜ì´ì§€ ë³¸ë¬¸ ë³´ê¸°"):
                    st.markdown(f'ì°¸ê³ í•œ í˜ì´ì§€ ë§í¬: {first_url}')
                    st.markdown(page_text if page_text else "_ë³¸ë¬¸ ì—†ìŒ_")
        except Exception as e:
            st.error("âŒ GPT ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.exception(e)

    st.session_state.chat_history.append(("ğŸ§‘â€ğŸ’¼ ì§ˆë¬¸", user_input))
    st.session_state.chat_history.append(("ğŸ¤– GPT", response))
    st.session_state.user_input = ""

# í‰ê°€ UI
# í‰ê°€ ìƒíƒœ ì²´í¬: í•œ ë²ˆ í‰ê°€í•˜ë©´ ë²„íŠ¼ ìˆ¨ê¸°ê³  ë©”ì‹œì§€ í‘œì‹œ
if "last_response" in st.session_state and st.session_state.last_response:
    st.markdown("### ğŸ“Š ì´ ë‹µë³€ì´ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”?")

    if st.session_state.get("feedback_done") is None:
        col1, col2 = st.columns(2)

        with col1:
            with st.form("form_up"):
                if st.form_submit_button("ğŸ‘ ë„ì›€ì´ ë˜ì—ˆì–´ìš”"):
                    save_feedback_to_supabase(
                        supabase_client,
                        st.session_state.last_input,
                        st.session_state.last_response,
                        st.session_state.last_issue,
                        "ğŸ‘"
                    )
                    st.session_state.feedback_done = "ğŸ‘"
                    st.rerun()

        with col2:
            with st.form("form_down"):
                if st.form_submit_button("ğŸ‘ ë¶€ì¡±í–ˆì–´ìš”"):
                    save_feedback_to_supabase(
                        supabase_client,
                        st.session_state.last_input,
                        st.session_state.last_response,
                        st.session_state.last_issue,
                        "ğŸ‘"
                    )
                    st.session_state.feedback_done = "ğŸ‘"
                    st.rerun()
    
    else:
        if st.session_state.feedback_done == "ğŸ‘":
            st.success("ê°ì‚¬í•©ë‹ˆë‹¤! ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤.")
        elif st.session_state.feedback_done == "ğŸ‘":
            st.warning("ì£„ì†¡í•©ë‹ˆë‹¤. ë” ë‚˜ì€ ë‹µë³€ì„ ìœ„í•´ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤.")

# í‰ê°€ í›„ ì´ˆê¸°í™”
if st.session_state.get("feedback_submitted", False):
    st.session_state.feedback_submitted = False
    st.session_state.last_input = ""
    st.session_state.last_response = ""
    st.session_state.last_issue = ""
    st.session_state.user_input = ""

def submit_question():
    st.session_state.trigger_gpt = True
    st.session_state.feedback_done = None

st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_input", on_change=submit_question)